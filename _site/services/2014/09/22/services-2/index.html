<!DOCTYPE html>
<html>
	
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="A Symposium on Notation for New Instruments and Musical Expression">
    <meta name="author" content="Thor Magnusson">
    
    <link rel="canonical" href="http://www.sonicwriting.org/ircam.html"/>

    <title>3D Device Mockups<br>by PSDCovers</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/landing-page.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="font-awesome-4.1.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="http://fonts.googleapis.com/css?family=Lato:300,400,700,300italic,400italic,700italic" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-70449773-6', 'auto');
  ga('send', 'pageview');

</script>

</head>

	<body>
		
<!-- Navigation -->
<nav class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand page-scroll" href="#home">New Notations</a>
        </div>
        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">  
            	<li>
                    <a class="page-scroll" href="#about">About</a>
                </li>
                <li>
                    <a class="page-scroll" href="#programme">Programme</a>
                </li>  
                <li>
                    <a class="page-scroll" href="#presenters">Presenters</a>
                </li>                                 
                <li>
                    <a class="page-scroll" href="#registration">Registration</a>
                </li>   
                <li>
                    <a class="page-scroll" href="#ircam">IRCAM</a>
                </li>
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>

<section id="home">
<!-- Header -->
	<div class="intro-header">

		<div class="container">

			<div class="row">
				<div class="col-lg-12">
					<div class="intro-message">
						<h1>3D Device Mockups<br>by PSDCovers</h1>
                        <br>
						<h2></h2>
                        <br>
                        <h3></h3>
                        <br>
                        <h4></h4>
                        <br><br>
						<hr class="intro-divider">
						<ul class="list-inline intro-social-buttons">
							
						</ul>
					</div>
				</div>
			</div>

		</div>
		<!-- /.container -->

	</div>
	<!-- /.intro-header -->
</section>

		    <!-- About Section -->
    <section id="about" class="container content-section text-left">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
            
            <br/><br/><br/>
            <h2>Symposium Theme</h2>

            <p>The New Notations Symposium at IRCAM explores current notational practices in the writing for new instruments and media. The aim is to study the changes in notational strategies that are brought forward with new music technologies, where graphics, animation, and algorithmic techniques offer extended compositional possibilities. Musical notation and instruments evolve in parallel, and we find that in much contemporary work, the notation system becomes part of the instrument, or even an integral part of the musical piece itself. Processor-based media enable dynamic score systems that are applied to generate musical events in real-time or respond to instrumental performances in ways traditional media are not capable of.</p>

            <p>Furthermore, with the increased analytical power gained with machine listening technologies, we find that auxillary notations of timbre, gesture, and affect become important aspects of the "writing" of a musical work. Contemporary composers study this potential of new notation, and this symposium looks into the design of new instruments from ergonomic and timbral perspectives and studies how musical notation develops in concert with these changes.
            </p>

            <p>Symposium topics include musical notation for new instruments, secondary notation, graphic or algorithmic notation, live and animated notation, usability, sustainability and legacy, tradition, issues of learning, audience communication, and more. The symposium consists of presentations, performances, and discussions. It is an open event, as long as space is available. For people interested in participating in the symposium, please fill in the registration form below.</p>

            <br>

            <p>Key topics during the day will address different aspects of musical instrumentalities: 

            <li>notation and tradition - how does a notational language evolve? 
            <li>new instruments - how does the role of notation change with new technologies? 
            <li>the symbol and the material - do new ergonomic and timbral affordances require new symbolism? 
            <li>the evolving instrument - how do we compose for evolving technologies? 
            <li>notation in screen-based and computational media - what are the qualities of dynamic scores?
            <li>graphic notation, live notation, animated notation - how does concept of "liveness" change?
            <li>education and learning - how do we learn new notations for new digital instruments? 
            <li>audience understanding - how do we communicate what a notation system does?
            <li>how does a notation system evolve, and how do we understand that evolution? 
            <li>what does a musical notation system mediate?
            </p>

        

            <br>
            <h2>Dates</h2>
            
            <p>
            - <b>September 22nd, 2016</b> : Symposium at <u><a href="http://www.ircam.fr/?&L=1">IRCAM</a></u>, Paris.<br></p>
             <br>
             <p>The symposium is part of a two-year <u><a href="http://www.ahrc.ac.uk">AHRC</a></u> funded research project, called <u><a href="http://www.sonicwriting.org">Sonic Writing</a></u>. The <u><a href="http://ismm.ircam.fr">Sound Music Movement Interaction</a></u> team at Ircam is a partner in the project.  

            <br/><br/><br/>

            </div>
        </div>
    </section>

		    <!-- Programme Section -->
        <section id="programme">
      <div class="dark-background">

      <div class="container content-section text-left">

        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
              
            <br/><br/><br/>

            
            <h2>PROGRAMME</h2>
                    
            <br>

            <p><b>The day's programme (Thursday, September 22nd) is the following:</b><br></p>

            <br>10:00 : Registration and coffee 
            <br>10:30 : Participant presentations (6 presentations - 10 min each) 
            <br>12:00 : Musical performance 
            <br>13:00 : Lunch Break
            <br>14:00 : Participant presentations (6 presentations - 10 min each) 
            <br>15:30 : Coffee & tea break
            <br>16:00 : Performances (improvisation and notation) 
            <br>17:00 : Roundtable discusson and summary of the day 
            <br>19.30 : Dinner 


            <br><br>
           
		 	<h4>PRESENTATIONS</h4>
                    
            <br><b>::: Morning session :::</b>
            <br><strong>Jonathan Impett</strong>: Notation as technology
            <br><strong>Sally Jane Norman</strong>: New Notations and Embodied Experience
            <br><strong>Enrique Tomás</strong>: Towards Non-linguistic Writing for Music: A Performative Approach
            <br><strong>Ryan Ross Smith</strong>: The Trappings of Choice: Mediating the Democratization of Participation through Control
            <br><strong>Franziska Schroeder</strong>: The absence of notation - exploring a haptic aurality
            <br><strong>Frédéric Bevilacqua</strong>: Perspective on notating and annotating expressive mouvements for interactive systems<br>

            <br><b>::: Afternoon session :::</b>
            <br><strong>Pavlos Antoniadis</strong>: Old notation, new interface: embodied navigation of complex piano notation with the GesTCom
            <br><strong>Dominique Fober</strong>: How technology affects the music score
            <br><strong>Claudia Molitor</strong>: A visual moment
            <br><strong>Einar Torfi Einarsson</strong>: Notation’s struggle to the surface (or, towards concrete notation)
            <br><strong>Frances-Marie Uitti</strong>: Signs and Symbols for a New Music
            <br><strong>Thor Magnusson</strong>: On Notating Algorithmic Machines
            <br><strong>Thierry Coduys</strong>: Playing the Sound Space<br>

            <br><br>
           
		 	<h4>PERFORMANCES</h4>
                    
            <br>

            <p><b>There will be two performance sessions during the day:</b><br></p>

            <br><b>::: First performance session :::</b>
            <br><strong>Enrique Tomás</strong>: Tangible Scores
            <br><strong>Ryan Ross Smith</strong>: Study no. 56
            <br><strong>Diemo Schwarz</strong>: Playing the Sound Space<br><br>
            
            <b>::: Second performance session :::</b>
            <br><strong>Sally Jane Norman</strong>: Object of Notation
            <br><strong>Pavlos Antoniadis</strong>: Learning Lemma-Icon-Epigram with GesTCom
            <br><strong>Group performance with Franziska Schroeder and others</strong>

            <br>
            <br/><br/><br/>

            </div>
        </div>
    </section>

		    <!-- PRESENTERS Section -->
    <section id="presenters" class="container content-section text-left">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
              
            <br/><br/><br/>
            <h2>PRESENTERS</h2>
                   
            <p><br>


            <br><hr>
            <h4><b>Enrique Tomás: Towards Non-linguistic Writing for Music: A Performative Approach</b></h4>

            In my talk, I will defend that representationalism has a history and that non-linguistic approaches for writing music might be an alternative for music notation. As Derrida states when referring to Pierce's philosophy of notation: “From the moment that there is meaning, there is nothing but signs. We think only in signs”. Our Western traditional music notation, a collection of related symbols with a given and arbitrary meaning, should be understood eminently as a linguistic technology, but more important, decoupled from our cognition of embodied artifacts. As a result, these representational systems are difficult to apply when, for example, our music is created for digital and interactive instruments, or when it incorporates phonetic (non-linguistic) content. I argue that a “performative” understanding of writing music, which shifts the focus from linguistic and visual representations to discursive practices, is one such alternative for suggesting new musical practices of notation.
            <br>

            <br><b>Biography</b><br>

            <a href="http://ultranoise.es/blog/">Enrique Tomás</a> (*1981) is a sound artist and researcher who dedicates his time to finding new ways of expression and play with sound, art and technology. His work explores the intersection between sound art, computer music, locative media and human-machine interaction. He has exhibited and performed throughout Europe and America at the spaces of ZKM, Ars Electronica, Sónar, SMAK, STEIM, etc. Tomás is also an active researcher on the field of new interfaces for musical expression. He is affiliated to the Interface Cultures department of the University of Art and Design of Linz, and his research has been presented at international peer-reviewed conferences like NIME, ICMC, SMC, TEI and TENOR. His artistic work has been supported and awarded with scholarships by Telefónica Vida, Phonos Foundation, the Academy of Fine Arts of Vienna and the Art Council of Madrid.<br><br>
  
            <div class="image-wrapper">
            <img src="img/enrique.jpg" alt="name" class="scale-image" />
            </div>


            <br><hr>
            <h4><b>Claudia Molitor: A visual moment</b></h4>

            As composers we naturally focus on sound as our main material, yet spend much of our time drawing – drawing notation. Whether with pen and paper or with notational software, we have much common gound with designers and architects at the early stages of our creative process: wrestling an as yet unrealised spatial and temporal idea onto the “two dimensional” space of the page/screen in order to communicate it to the interpreter(s); whether they be makers in the case of design, builders in the case of architecture or performers in the case of music. It is with notation that some composers challenge conventions and beliefs about musical practice; in their work the score becomes both a ‘script’ to be interpreted as well as a conceptual space. It is the demands of the sonic possibilities, technologies or imaginations as well as the notational systems used, which in turn influence the composer’s thinking… a feedback loop between the sonic and the visual.<br>

            <br><b>Biography</b><br>

            <a href="http://www.claudiamolitor.org">Claudia Molitor</a> is a composer/artist whose work draws on traditions of music and sound art but also extends to video, performance and fine art practices. Exploring the relationships between listening and seeing as well as embracing collaboration as compositional practice is central to this work. Her work is regularly commissioned, performed and broadcast throughout Europe. Recent work includes Sonorama with Electra Productions, Turner Contemporary and the British Library, Vast White Stillness for Spitalfields Festival and Brighton Festival, and 2TwoLO for NMC’s ‘Objects of an Exhibition’ project with the Science Museum. She is currently working with MusikFabrik for a piece for hcmf// 2016 and The Singing Bridge will run over three weeks at Totally Thames this September, with a digital download release on NMC. <br><br>
  
            <div class="image-wrapper">
            <img src="img/claudia.jpg" alt="name" class="scale-image" />
            </div>


            <br><hr>
            <h4><b>Frederic Bevilacqua: Perspective on notating and annotating expressive mouvements for interactive systems</b></h4>

            I will present and discuss some current issues on movement notation for interactive systems. The growing use of interactive machine learning with new musical interfaces brings new opportunities for movement notation and annotation. It also poses new difficulties, which interestingly should lead us to question and propose novel notation approaches.<br>

            <br><b>Biography</b><br>

            <a href="http://frederic-bevilacqua.net">Frédéric Bevilacqua</a> is the head of the Sound Music Movement Interaction team at IRCAM in Paris. His research concerns the modeling and the design of interaction between movement and sound, and the development of gesture-based interactive systems. He holds a master degree in physics and a Ph.D. in Biomedical Optics from EPFL in Lausanne. He also studied music at the Berklee College of Music in Boston and has participated in different music and media arts projects. From 1999 to 2003 he was a researcher at the Beckman Laser Institute at the University of California Irvine. In 2003 he joined IRCAM as a researcher on gesture analysis for music and performing arts.
            <br><br>
  
            <div class="image-wrapper">
            <img src="img/frederic.jpg" alt="name" class="scale-image" />
            </div>


            <br><hr>
            <h4><b>Frances-Marie Uitti: Signs and Symbols for a New Music</b></h4>

            Designing a comprehensive notation for a new musical technology:  in particular the challenge of notation for a new musical gesture controller that supports conventional and extended two-bow cello playing with the unusual feature that it has no strings. Given the unique problems inherent with a huge flow of musical data, separating the various complexities into manageable and readable format, I am approaching musical notation as a fluid and fluent set of flowing systems that is constantly changing according to the needs of each musical situation or composition. 
            <br>

            <br><b>Biography</b><br>

            <a href="http://www.uitti.org">Frances-Marie Uitti</a>, composer/performer, pioneered a revolutionary dimension to the cello by transforming it for the first time into a polyphonic instrument capable of sustained chordal (two, three, and four-part) and intricate multivoiced writing. Using two bows in one hand, this invention permits contemporaneous cross accents, multiple timbres, contrasting 4-voiced dynamics, simultaneous legato vs articulated playing. György Kurtág, Luigi Nono, Giacinto Scelsi, Jonathan Harvey, Richard Barrett, Horatio Radulescu, Lisa Bielawa are among many who have used this technique in their works dedicated to her. 
            <br><br>
  
            <div class="image-wrapper">
            <img src="img/frances.jpg" alt="name" class="scale-image" />
            </div>

            <br><hr>
            <h4><b>Jonathan Impett: Notation as technology</b></h4>

            The technologies – codes and materials – of inscription play a vital role in forming musical objects and practices, and crucially inform the discourses of music. Many current issues can be traced back to the beginning of the C20th, to the beginning of what has been described in architecture as an ‘age of divided representation’. An extraordinary property of common Western music notation has been its multiple functions: manipulation, representation, description, instruction and analysis for the same musical material can all be carried out using the same notational system. As with literacy, Western notation thus entered the cognitive processes associated with music, even in the absence of material text. Notation continues to inform musical thought, at all stages of a work’s existence. However, we cannot assume the same multivalency. In considering notational practices for the creation and performance of today’s hybrid musical objects, we must re-evaluate its role. Conventional assumptions are challenged by actual practice. Notation may best be viewed as a technology, and a crucial node in a network of technologies among which we must count human technical skills. Notation is a central node in the unique  pattern of determination, distribution and dissemination that characterizes each musical object.  <br>

            <br><b>Biography</b><br>

            <a href="http://www.orpheusinstituut.be/en/persons/jonathan-impett">Jonathan Impett</a> studied at the University of London, City University, Royal Academy of Music , Schola Cantorum Basiliensis, and University of Cambridge. He is Director of Research at the Orpheus Institute, Ghent and Associate Professor at Middlesex University, London. His compositions explore the spaces between score and improvisation, most recently using prepared acoustics and wave phenomena as a way of integrating symbolic-compositional, sound processing and improvisational materials. Early work with the computer-extended metatrumpet has led to a continuing engagement with interactive technologies and the acts and contexts of performance. As a trumpet player he has given premieres of solo works by composers including Berio, Harvey and Scelsi, as well as performing with ensembles such as London Sinfonietta and Apartment House and in various improvisational contexts. He is also a member of The Orchestra of the Eighteenth Century and The Amsterdam Baroque Orchestra. His research is also concerned with the discourses and practices of contemporary musical creativity, particularly the nature of the contemporary technologically-situated musical artefact: ‘The work without content’. A monograph on the music of Luigi Nono will appear in 2017. He leads a new research cluster at the Orpheus Institute, 'Music, Thought and Technology’, taking a critical technical practice approach to understanding musical creativity.<br><br>

            <div class="image-wrapper">
            <img src="img/jonathan.jpg" alt="name" class="scale-image" />
            </div>


            <br><hr>
            <h4><b>Franziska Schroeder: The absence of notation - exploring a haptic aurality</b></h4>

            Notation marks and explains, it communicates and documents, it prescribes and produces. Within such notational possibilities signs are able to formalise, to solidify but also to expand practice.  And while the ritual of performance practices in Classical Music might be seen as highly regulated, in which the performer is often posited as a self-effacing, faithful servant to the notated work, there exist certain practices, including free music improvisation, that not only question notation (and much more!) but that revel in the absence of notational signs. Taking as a starting point Jean-Louis Schefer’s idea of a ʻpractice of notationʼ (1995), I want to think of notation as a colouring of signs, rather than an execution of signs, but going further, I will examine the absence of notation in some improvisational practices and argue that an absence of notational concepts allows performers the creative space for turning inward and for straining towards self (Nancy, 2002). This turning inward becomes a highly intimate, tactile or haptic listening space (examined as haptic aurality in Schroeder, 2009) that not only involves constructing and consolidating the self, urging the performer to be in a constant state of being on the ‘lookout for a relation to self’, it also allows the performer in rejoicing in her body, in noticing her presence and in being self preoccupied in a very tangible relation with her tools. Since I understand free improvisational practices as creative and social exchanges between musicians anchored in high levels of trust, I want to consider music practices that question or ignore notational signs as practices that allow for a deeper reverence for musical, cultural and social engagements with others. With the introduction of computer models into free improvisation practices (the use of Probabilistic Graphical Models, such as Bayesian and Markov networks, as explored in Kalonaris in 2016), we see a return to a desire for notational instructions. Such turn towards imposing notational frameworks counters the socio-political spirit of some of the original ideas of what is meant to be ‘free’, while it shifts the musician’s focus towards the visual sign. Where this move towards a more regulated notational framework will lead free improvisers is yet to be seen - it is certainly a journey that some musicians take reluctantly, always in the hope that the notational signs will further expand, rather than solidify, their practice.
            <br>

            <br><b>Biography</b><br>

            <a href="http://www.socasites.qub.ac.uk/fschroeder/">Franziska Schroeder</a> trained as a contemporary saxophonist in Australia, and in 2006 completed her PhD at the University of Edinburgh, researching performance and theories of embodiment. Her research is published in international journals, including Leonardo, Organised Sound, Performance Research, Cambridge Publishing and Routledge. Franziska has published a book on performance and the threshold (2009), an edited volume on user-generated content (Cambridge Scholars Publishing, 2009) as well as a volume on improvisation (Cambridge Scholars Publishing, 2014). Franziska is a Senior Lecturer at the School of Arts, English and Modern Languages at Queen’s University Belfast, where she coaches students in improvisation, digital performance and critical theory. She has been the Artistic Director for the 2012 Sonorities Festival of Contemporary music and is directing the festival again in 2016.

            <br><br>
  
            <div class="image-wrapper">
            <img src="img/franziska.jpg" alt="name" class="scale-image" />
            </div>
            

            <br><hr>
            <h4><b>Sally Jane Norman: New Notations and Embodied Experience</b></h4>

            The mechanical vibrations we shape and apprehend as artistic sound lend themselves to potentially infinite kinds of notation. Systems devised to plot, store, and recreate sonic events are more or less context-bound: western classical scores consolidated by centuries of academic practice presume set instrumental and interpretive parameters, while open processes integral to recent electronics and digital techniques require very different compositional and notational approaches. Yet despite the conjoined cognitive and technological evolution associated with the latter practices, our sense of rhythm and scale remains anchored in corporeal morphologies and dynamics, in psychophysiological projections of effort and intentionality into the most ostensibly abstract domains. However strange they may seem, creative acts can only be grasped, thus notated, via our inevitably anthropomorphising sensibility. This presentation emphasises the need to build embodied experience - notably gesture and touch - into new notational strategies.<br>

            <br><b>Biography</b><br>

            <a href="http://www.sussex.ac.uk/profiles/240005">Sally Jane Norman</a> (Aotearoa-NZ/France), performing arts historian and practitioner, holds a Doctorat d'état from the Institut d'études théâtrales, Paris III. Previous roles include direction of the 1993 Louvre New Images Symposium and 1994 motion capture workshop at the Institut International de la Marionnette (Charleville-Mézières), and research at the Zentrum für Kunst und Medientechnologie (Karlsruhe). As Artistic Co-Director of STEIM (Studio for Electro-Instrumental Music, Amsterdam) she co-organised the 1998 Touch Festival with Michel Waisvisz and Joel Ryan. She led the Ecole européenne supérieure de l'image (Angoulême-Poitiers), moving to Newcastle University in 2004 to found Culture Lab. From 2010 she steered a major cultural centre renovation as Professor of Performance Technologies at the University of Sussex, where since 2015 she leads Digital Performance as founding Co-Director of Sussex Humanities Lab. <br><br>
  
            <div class="image-wrapper">
            <img src="img/sallyjane.jpg" alt="name" class="scale-image" />
            </div>

         
            <br><hr>
            <h4><b>Pavlos Antoniadis : Old notation, new interface: embodied navigation of complex piano notation with the GesTCom</b></h4>

            The evolution of traditional notation towards increased specificity and complexity has been expanding its role from the composer’s “brain in a vat” into an elastic interface dynamically amalgamated with instruments and performing bodies. In that sense, a Xenakis or Ferneyhough score is inviting interaction more than interpreta-tion, navigation more than understanding. At the same time, new technologies such as the ones for gesture capture and interactive notation are allowing for the materialisation of metaphors into actual multimodal notations. Along these lines, I will present a model of embodied interaction with complex piano notation (embodied navigation) and a prototype system for the gestural processing of musical scores (GesTCom -Gesture Cutting through Textual Complexity). The first approaches notation through concepts in the field of embodied cognition, the latter integrates views from NIME and CHI into a gesturally controlled interface for notation processing.<br>

            <br><b>Biography</b><br>

            <a href="https://pavlosantoniadis.wordpress.com/about">Pavlos Antoniadis</a> is a Berlin-based new music pianist & a PhD candidate at Ircam and Labex Gream under the supervision of F. Bevilacqua and P. Michel. He has performed in Europe, the Americas and Asia with Work in Progress-Berlin, KNM, Phorminx, Ergon and as a soloist. He has recorded for Mode (2015 Deutscheschallplat-tenkritikspreis) and Wergo records. He has published on embodied cognition, gesture capture and piano per-formance and has been invited to lecture at institutions such as Goldsmiths London, INMM Darmstadt, Orcim Gent, Ircam Paris, Conservatoire Strasbourg, Aristoteleio Thessaloniki, Hong Kong University. He was a Musical Research Residency fellow at Ircam in 2014. Pavlos holds degrees in piano performance (MA, UC San Diego) and musicology (Athens National University) and has studied on Gream, Fulbright, Ucsd, Nakas, IEMA Frankfurt and Impuls Academy Gratz scholarships.<br><br>
  
            <div class="image-wrapper">
            <img src="img/pavlos.jpg" alt="name" class="scale-image" />
            </div>


            <br><hr>
            <h4><b>Einar Torfi Einarsson: Notation’s struggle to the surface (or, towards concrete notation)</b></h4>

            Notation is a system within a system. It has evolved in between or amidst the composer and the performer/instrument and has had a clear position (composer-score-performer), functionality (communication tool and performer engagement), and directionality (towards performative sonic results). Despite its multifarious paths and appearances it has remained in the background or as a secondary aspect of music (sound being dominant). But could notation denature or leave behind its symbolism, its reference system or its place in the system it evolved within? Does it have an escape route? In this talk I will trace and propose a (im)possible evolution of a strand of notation called prescriptive notation and explore another notational directionality, leading to experimental fusion of material and notation, or something I’m calling concrete notation where notation examines and questions its own functionality and history.<br>

            <br><b>Biography</b><br>

            <a href="http://einartorfieinarsson.com">Einar Torfi Einarsson</a> is a composer and researcher. He obtained his Ph.D. from the University of Huddersfield where he studied on the Jonathan Harvey Scholarship. His music has been performed throughout Europe by ensembles such as ELISION Ensemble, Klangforum Wien and Ensemble Intercontemporain. His research interests lie in the interplay of poststructuralist philosophy and notation through which he has been developing the notion of decontextualized notation and concrete notation. In 2013-14 he was a post-doc Research Fellow at the Orpheus Institute (ORCiM, Ghent, Belgium). Currently he is a Lecturer in Composition at the Iceland Academy of the Arts.<br><br>
  
            <div class="image-wrapper">
            <img src="img/einar.jpg" alt="name" class="scale-image" />
            </div>



            <br><hr>
            <h4><b>Ryan Ross Smith: The Trappings of Choice: Mediating the Democratization of Participation through Control</b></h4>

            The development, formalization, codification, and maintenance of common practice notation [CPN] demonstrates a parallel yet intertwined tract to the evolution of musical thought and practice, and while CPN is not the only Western notational approach in existence, it is dominant. Following in line with the various revisions to and extensions of CPN, a new form of niche-notation has been increasing in visibility over the last 15 years: Animated Music Notation [AMN]. Certain trends in contemporary animated scoring practices demonstrate a dismantling of the normative expectations of the score-performer relationship. Namely, that choice, and its trappings (the interpretive expectations placed on performers for example), are discarded in favor of control structures that democratize musical participation, while encouraging, if not requiring, a curiously submissive relationship to the score’s ephemeral dominance. Furthermore, these methods of representation tend to encourage certain compositional ideals beyond those embedded within traditionally-dominant notational models.
            <br>

            <br><b>Biography</b><br>

            <a href="http://www.ryanrosssmith.com">Ryan Ross Smith</a> is a composer and performer currently based in Fremont Center, NY. Smith has performed throughout the US, Europe and UK, including performances at MoMA and PS1 [NYC] and Le Centre Pompidou [Paris, FR], has had his music performed throughout North America, Iceland, Denmark, Australia and the UK, has presented his work and research at conferences including NIME, ISEA, ICLI, the Deep Listening Conference and Tenor, and has lectured at various colleges and universities. Smith is best known for his work with Animated Music Notation, and his research website <a href="http://www.animatednotation.com">animatednotation.com</a> (please visit <a href="http://animatednotation.wordpress.com">animatednotation.wordpress.com</a> for more regular updates). Smith earned his PhD in Electronic Arts from the Rensselaer Polytechnic Institute in Troy, NY in August, 2016 <br><br>
  
            <div class="image-wrapper">
            <img src="img/ryan.jpg" alt="name" class="scale-image" />
            </div>



            <br><hr>
            <h4><b>Dominique Fober: How technology affects the music score</b></h4>

            New technologies pose new challenges for the music score: interactive music, new instruments, mixed medias, purely gesture based performances, are among the domains explored by the contemporary creation that overflow the classical frame of the music notation. On another other side, new systems for music notation and representation are emerging, adressing these challenges, proposing also new ways to represent the music, exploiting the specific dimensions of digital scores. Dynamicity, interactivity are part of the new dimensions of the music score that lead to new musical forms. I will present and discuss these issues and how they are addressed in my current research.<br>

            <br><b>Biography</b><br>

            Dominique Fober has both a scientific and musical background. He is doing computer music research at Grame - National Center for Music Creation based in Lyon, France - for over 20 years. His research is concerned mainly with software architecture for real-time music systems, languages for musical composition, and music notation and representation systems. He has created, as author or joint author, many musical systems and programs. His most recent work focuses on the extension of the music score, with the aim of covering the needs of the contemporary music creation, as well as  those of technology enhanced music pedagogy.
            <br><br>
  
            <div class="image-wrapper">
            <img src="img/dominique.jpg" alt="name" class="scale-image" />
            </div>



            <br><hr>
            <h4><b>Thor Magnusson: On Notating Algorithmic Machines</b></h4>
            
            Live coding has been defined as a new path in the evolution of the musical score. Live coding practice accentuates the score, and whilst it is the perfect vehicle for the performance of algorithmic music, it also transforms the compositional process itself into a live event. As a continuation of 20th Century artistic developments of the musical score, live coding systems often embrace graphical elements and language syntaxes foreign to standard programming languages. This talk will presents live coding as a highly technologized artistic practice, shedding light on how non-linearity, play and generativity are prominent in live coding performance practice.
            <br>

            <br><b>Biography</b><br>

            <a href="http://thormagnusson.github.io">Thor Magnusson</a> is a lecturer in Music at the University of Sussex. His work focusses on the impact digital technologies have on musical creativity and practice, explored through software development, composition and performance. He is the co-founder of ixi audio, and has developed audio software, systems of generative music composition, written computer music tutorials and created two musical live coding environments. As part of ixi, he has taught workshops in creative music coding and sound installations, and given presentations, performances and visiting lectures at diverse art institutions, conservatories, and universities internationally.<br><br>
      

            <div class="image-wrapper">
            <img src="img/thor_magnusson.jpg" alt="Thor Magnusson" class="scale-image" />
            <div />




            <br><hr>
            <h4><b>Thierry Coduys: Notating with IanniX - Score in space and time</b></h4>
            
            IanniX is a graphical real-time open-source sequencer, based on Iannis Xenakis works, for digital art. Its graphical space spans several dimensions and time scales. Using a palette of fundamental objects such as triggers (events), curves (trajectories in space) and cursors (progression over time), IanniX provides a graphical and interactive representation of time in the 3D space and ensures a bidirectional exchange across multiple communication protocols, including OSC. In this presentation I will discuss the ideas that led to the design of IanniX and why we thought this system solves some of the problems of notation in the ecosystem of current musical technologies. 
            <br>

            <br><b>Biography</b><br>

            Artist, musician, new technology expert, <a href="http://www.ens-louis-lumiere.fr/formation/formation-initiale-cinema-son-photographie/enseignants/thierry-coduys.html">Thierry Coduys</a> specializes in collaborative and multidisciplinary projects where interactivity meets the contemporary arts. Since 1986, he has worked closely with the avant-garde of contemporary music (e.g. Karlheinz Stockhausen, Steve Reich, etc.) to realise electro-acoustic and computer systems for live performance and installation. After a few years spent at the IRCAM in Paris as a researcher, he becomes Luciano Berio’s assistant. Building on his experience of the contemporary art scene, he creates his own structure in 1999: an artistic research and technology centre called ‘La kitchen’, where artists from a variety of disciplines (e.g. music, dance, theatre, video, network) can come and develop projects in collaboration with the team. In 2007, Thierry launches ‘le hub’ as he endeavours to carry out his projects within a fresh, flexible and open framework. ‘Le hub’ is a platform for reflection and experimentation as well as the central piece of a network through which a diversity of artistic, scientific and engineering disciplines are being brought together. Thierry Coduys is currently collaborating with French composer Pascal Dusapin (since 2002), with I alian composer Ivan Fedele (since 2000), as well as with Marc Monnet (since the 80’s) and theatre director Jean-François Peyret (since 2001). He is also member of AFIM’s (The French computer music organization) board of trustees, consultant for OSEO (French governmental organization for supporting innovation) and course director (sound scenography) at ENS Louis Lumière (France’s audio engineering school). Finally, Thierry is developing ‘IanniX’ (GNU GPL application), an interactive software interface, inspired by the UPIC of Iannis Xenakis.<br><br>
      

            <div class="image-wrapper">
            <img src="img/thierry.jpg" alt="Thierry Coduys" class="scale-image" />
            <div />


            <br/><br/><br/>
        
            </div>
        </div>
    </section>

		    <!-- Registration Section -->
    <section id="registration">
      <div class="dark-background">

      <div class="container content-section text-left">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
            
            <br/><br/><br/>

        <h2>Registration</h2>
        
        <p>Participation in the symposium is open and we encourage people from diverse fields of practice to come along and think about the role of instrument desing in artistic practice. There will be time during the round table and discussion for an open dialogue.</p>

        <p>Registration is free, but we ask people to fill in the form below in order to have people's emails, and to keep track of numbers.</p>

        <div class="iframe-rwd">

        <iframe src="https://docs.google.com/forms/d/1dYcofkEwdAiGFFjPK7Tf6yR7uOmH2JjNqkiyBSnkI1U/viewform?embedded=true" width="760" height="500" frameborder="0" marginheight="0" marginwidth="0">Loading...</iframe>
        </div>

        <br> <br>
        <p>Registration also available through the <a href= "https://docs.google.com/forms/d/1dYcofkEwdAiGFFjPK7Tf6yR7uOmH2JjNqkiyBSnkI1U/viewform" target="_blank"> Google Form</a> (in a new window).
        </p>

        <br>Welcome!

              
            <br/><br/><br/>

            </div>
        </div>
    </section>

		<section id="ircam"> 
	<div class="banner">
        <div class="container content-section text-left">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2">
		
				<div>
                <br/><br/><br/>
			    <h2><span style="background-color: #242424">IRCAM</span></h2>
                
                <p> <span style="background-color: #242424">IRCAM, the Institute for Research and Coordi- nation in Acoustics/Music, is one of the world’s largest public research centers dedicated to both musical expression and scientific research. A unique location where artistic sensibilities col- lide with scientific and technological innovation, Frank Madlener has directed the institute since 2006, bringing together over 160 people.</span></p>

                <p> <span style="background-color: #242424">IRCAM’s three principal activities — creation, research, transmission — are visible in IRCAM’s Parisian concert season, in productions through- out France and abroad, in a new rendezvous cre- ated in June 2012, ManiFeste, that combines an international festival with a multidisciplinary academy.</span></p>

                <p> <span style="background-color: #242424">Founded by Pierre Boulez, IRCAM is associated with the Centre Pompidou, under the tutelage of the French Ministry of Culture and Communi- cation. The mixed STMS research lab (Sciences and Technologies for Music and Sound), housed by IRCAM, also benefits from the support of the CNRS and the University Pierre and Marie Curie, as well as Inria (team-project MuTant).</span></p>


<br><span style="background-color: #242424">Further information on the <a href="http://www.ircam.fr">IRCAM website</a></span>.

<br><br><span style="background-color: #242424">Address: 1, place Igor-Stravinsky, 75004 Paris.</span>

<br><br><span style="background-color: #242424">Métro : Hôtel de Ville, Rambuteau, Châtelet, Les Halles</span>

<br><br><span style="background-color: #242424">Ircam is next to the famous Centre Pompidou and should be easy to find.</span>



                </p>
        <div class="iframe-rwd">

<iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2624.915616195975!2d2.3492132156840984!3d48.859819479287594!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x47e66e1c3dd0b877%3A0xe54b44663bd2e7ff!2sInstitute+for+Music%2FAcoustic+Research+%26+Coordination+(IRCAM)!5e0!3m2!1sen!2suk!4v1468164386649" width="600" height="450" frameborder="0" style="border:0" allowfullscreen></iframe>
    </div>


<!--
                <iframe src="https://www.google.com/maps/embed?pb=!1m34!1m12!1m3!1d2518.193841568312!2d-0.08913922271244629!3d50.8646110571229!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!4m19!3e2!4m5!1s0x487588b510bc27bb%3A0x29a07b41468f59f7!2sAttenborough+Centre%2C+Falmer%2C+Brighton+BN1+9QF%2C+UK!3m2!1d50.864559899999996!2d-0.0899116!4m5!1s0x487588ca9c6619bf%3A0x97937c332c494df4!2sSilverstone%2C+Brighton+BN1+9RG%2C+UK!3m2!1d50.8667403!2d-0.0898736!4m5!1s0x487588b415ac8927%3A0xa22a0eee0abb868e!2sStation+Approach%2C+Falmer%2C+Brighton+BN1+9SD%2C+UK!3m2!1d50.8624583!2d-0.0872725!5e0!3m2!1sen!2suk!4v1436347084758" width="750" height="450" frameborder="0" style="border:0" allowfullscreen></iframe>
                </p>
  -->               

                                  <br/><br/>

                <ul class="list-inline banner-social-buttons">
                    
                </ul>

             <br/><br/><br/><br/>
			</div>
        </div>
    </div>
	</div>
	</div>
</section>
<!-- /.banner -->
		<!-- Footer -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-70449773-1', 'auto');
  ga('send', 'pageview');

</script>

<footer>
    <div class="container">
        <div class="row">
            <div class="col-md-4">
                <ul class="list-inline">
                    <li>
                        <a href="#home">Home</a>
                    </li>
                    <li class="footer-menu-divider">&sdot;</li>
                    <li>
                        <a href="#about">About</a>
                    </li>
                    <li class="footer-menu-divider">&sdot;</li>
                    <li>
                        <a href="#programme">Programme</a>
                    </li>
                    <li class="footer-menu-divider">&sdot;</li>
                    <li>
                        <a href="#presenters">Presenters</a>
                    </li>
                    <li class="footer-menu-divider">&sdot;</li>
                    <li>
                        <a href="#registration">Registration</a>
                    </li>

                    <li class="footer-menu-divider">&sdot;</li>
                    <li>
                        <a href="#ircam">IRCAM</a>
                    </li>

                </ul>
                <p class="copyright text-muted small">Copyright &copy; Thor Magnusson, ISMM team, STMS Lab IRCAM-CNRS-UPMC. All Rights Reserved.</p>
                <p class="copyright text-muted small">The symposium is part of a two-year <a href="http://www.ahrc.ac.uk">AHRC</a> funded research project, called <a href="http://www.sonicwriting.org">Sonic Writing</a>. Chair: Thor Magnusson (University of Sussex) invited by the <a href="http://ismm.ircam.fr">ISMM team</a>, STMS Lab, IRCAM-CNRS-UPMC.</p>
                <br>
                

            </div>

             <div class="col-md-4">
                <img src="img/ahrc.png" alt="AHRC" class="scale-image" />
                <img src="img/ahrc_logo.jpg" alt="AHRC logo" style=" height:75px;"> 
<img src="img/ircam.gif" alt="IRCAM logo" style="height:75px;">
<br>
<img src="img/cnrs.jpg" alt="Mountain View" style=" height:75px;"> 
<img src="img/upmc.jpg" alt="Mountain View" style="height:75px;">

            </div>

  
            <div class="col-md-4">
                <b>Credits:</b> The figure on the Symposium's entry page from Einar Torfi Einarsson's <a href="https://prezi.com/4opoxg6q_7bz/desiring-machines/" target="_blank"> Desiring Machines</a> piece. The picture of IRCAM is by Maureen (Flickr: IRCAM at Beaubourg) [CC BY 2.0 (http://creativecommons.org/licenses/by/2.0)] via Wikimedia Commons.
            </div>
        </div>
    </div>
</footer>

		<!-- jQuery Version 1.11.0 -->
<script src="js/jquery-1.11.0.js"></script>

<!-- Plugin JavaScript -->
    <script src="js/jquery.easing.min.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="js/bootstrap.min.js"></script>

<!-- Custom Theme JavaScript -->
<script src="js/landing-page.js"></script>

	</body>
</html>
